{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian Mixture Model & Expectation - Maximization Algorithm\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from ipysketch import Sketch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "sk = Sketch('gmm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "Button(description='Edit', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d50da0df685403cb9b98effe244afc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2204d9dc94f459083d16e71c9dbd7d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![gmm](../contents/gmm.PNG)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variables explanations\n",
    "\n",
    "* $\\pi_k$: probability of grabbing a sample from distribution $k$ (in this case Gaussian $k$)\n",
    "* $N(\\vec{x}_n | \\mu_k, \\Sigma_k)$: given Gaussian distribution parameters mean ($\\mu_k$), and covariance ($\\Sigma_k$), the probability of getting a sample result $\\vec{x}_n$\n",
    "* $\\gamma_{nk}$: Given that we have got a sample $\\vec{x}_n$, the probability that this sample comes from distribution $k$. (Note this is derived from Bayes rule: $\\gamma_{nk} := p(z_k | \\vec{x}_n) \\propto p(\\vec{x}_n | z_k)\\cdot p(z_k) = N(\\vec{x}_n | \\mu_k, \\Sigma_k) \\cdot \\pi_k$\n",
    "* $T_n$: probability of grabbing a sample result $\\vec{x}_n$ from the whole population\n",
    "* $p(\\vec{X})$: probability of achieving a consecutive results $(\\vec{x}_1, \\vec{x}_2, ..., \\vec{x}_N)$ (since we assume each experiment is independent), this term is called **likelihood**\n",
    "* $\\ln p(\\vec{X})$: the **log-likelihood**\n",
    "* $N_k$: probability that the consecutive results $(\\vec{x}_1, \\vec{x}_2, ..., \\vec{x}_N)$ come from distribution $k$\n",
    "* $(\\pi_k^*, \\mu_k^*, \\Sigma_k^*)$: updated parameters\n",
    "\n",
    "## 3 steps of expectation-maximization algorithm (iterative method)\n",
    "\n",
    "1. In *Initialization step*,  we must initialise our parameters $(\\pi_k, \\mu_k, \\Sigma_k)$. In this case, we are going to use the results of KMeans as an initial value for $\\mu_k$, set $\\pi_k$ to one over the number of clusters and $\\Sigma_k$ to the identity matrix. We could also use random numbers for everything, but using a sensible initialisation procedure will help the algorithm achieve better results.\n",
    "\n",
    "2. In *Expectation step*, we calculate the matrix elements $\\gamma_{nk}$. This is the *expected values* from our guess of the parameters $(\\pi_k, \\mu_k, \\Sigma_k)$.\n",
    "\n",
    "3. In *Maximization step*, we update the parameters to $(\\pi_k^*, \\mu_k^*, \\Sigma_k^*)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Ref\n",
    "\n",
    "1. [知乎：【机器学习】EM——期望最大（非常详细）](https://zhuanlan.zhihu.com/p/78311644)\n",
    "2. [GMM Implementation](https://github.com/ocontreras309/ML_Notebooks/blob/master/GMM_Implementation.ipynb)\n",
    "3. [Gaussian Mixture Models Explained](https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
