{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1 style=\"color:orange\">Hidden Markov Model (HMM) </h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1373806364.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    <h1 style=\"color:orange\">Hidden Markov Model (HMM) </h1>\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "<h2 style=\"color:orange\">Markov Model (MM) </h2>\n",
    "\n",
    "A Markov Model is a stochastic state space model involving random transitions between states where the probability of the jump is only dependent upon the current state, rather than any of the previous states. The model is said to possess the Markov Property and is <span style=\"color:orange\">\"memoryless\"</span>. Random Walk models are another familiar example of a Markov Model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "<h2 style=\"color:orange\">Markov Family </h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ipysketch import Sketch\n",
    "sk = Sketch('hmm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, the HMM has two hidden states ('H1' and 'H2') and three possible observations ('O1', 'O2', and 'O3'). The start probabilities, transition probabilities, and emission probabilities are defined in the start_prob, transition_prob, and emission_prob dictionaries, respectively. The sequence of observations is obs_seq.\n",
    "\n",
    "The viterbi function implements the Viterbi algorithm to find the most likely sequence of hidden states given the sequence of observations. It takes the sequence of observations, the possible hidden states, and the HMM parameters as inputs and returns the most likely sequence of hidden states.\n",
    "\n",
    "Finally, the script calls the viterbi function with the given inputs and prints the most\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely sequence of hidden states: ['H2', 'H2', 'H1', 'H1']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the HMM parameters\n",
    "hidden_states = ['H1', 'H2']\n",
    "observations = ['O1', 'O2', 'O3']\n",
    "start_prob = {'H1': 0.6, 'H2': 0.4}\n",
    "transition_prob = {'H1': {'H1': 0.7, 'H2': 0.3}, 'H2': {'H1': 0.4, 'H2': 0.6}}\n",
    "emission_prob = {'H1': {'O1': 0.1, 'O2': 0.4, 'O3': 0.5}, 'H2': {'O1': 0.6, 'O2': 0.3, 'O3': 0.1}}\n",
    "\n",
    "# Define the sequence of observations\n",
    "obs_seq = ['O1', 'O1', 'O2', 'O3']\n",
    "\n",
    "# Implement the Viterbi algorithm\n",
    "def viterbi(obs_seq, hidden_states, start_prob, transition_prob, emission_prob):\n",
    "    T = len(obs_seq)\n",
    "    N = len(hidden_states)\n",
    "\n",
    "    # Initialize the probability matrix and the backpointer matrix\n",
    "    prob = np.zeros((T, N))\n",
    "    backpointer = np.zeros((T, N), dtype=int)\n",
    "\n",
    "    # Set the initial probabilities\n",
    "    for s in range(N):\n",
    "        prob[0][s] = start_prob[hidden_states[s]] * emission_prob[hidden_states[s]][obs_seq[0]]\n",
    "\n",
    "    # Calculate the probabilities for each time step\n",
    "    for t in range(1, T):\n",
    "        for s in range(N):\n",
    "            max_prob = 0\n",
    "            max_state = 0\n",
    "            for s_prev in range(N):\n",
    "                curr_prob = prob[t-1][s_prev] * transition_prob[hidden_states[s_prev]][hidden_states[s]] * emission_prob[hidden_states[s]][obs_seq[t]]\n",
    "                if curr_prob > max_prob:\n",
    "                    max_prob = curr_prob\n",
    "                    max_state = s_prev\n",
    "            prob[t][s] = max_prob\n",
    "            backpointer[t][s] = max_state\n",
    "\n",
    "    # Find the path with the highest probability\n",
    "    max_prob = max(prob[T-1])\n",
    "    max_state = np.argmax(prob[T-1])\n",
    "    path = [hidden_states[max_state]]\n",
    "    for t in range(T-1, 0, -1):\n",
    "        max_state = backpointer[t][max_state]\n",
    "        path.insert(0, hidden_states[max_state])\n",
    "\n",
    "    return path\n",
    "\n",
    "# Find the most likely sequence of hidden states\n",
    "path = viterbi(obs_seq, hidden_states, start_prob, transition_prob, emission_prob)\n",
    "print(\"Most likely sequence of hidden states:\", path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}